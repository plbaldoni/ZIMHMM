{
    "collab_server" : "",
    "contents" : "vecData = function(data,N,control=T,random=F){\n    data <- data.table::copy(data)\n    if(!random){\n        if(control){\n            return(melt(data[,unique(c(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('Dsg.Control.',1:sum(grepl('^Dsg.Control',names(data)))),paste0('offset.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N))),with=F],\n                        measure = list(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('Dsg.Control.',1:sum(grepl('^Dsg.Control',names(data)))),paste0('offset.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N)),\n                        value.name = c('ChIP','Dsg.Int','Dsg.Control','offset','PostProb1','PostProb2','Rejection1','Rejection2'))[,-1])\n        } else{\n            return(melt(data[,unique(c(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('offset.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N))),with=F],\n                        measure = list(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('offset.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N)),\n                        value.name = c('ChIP','Dsg.Int','offset','PostProb1','PostProb2','Rejection1','Rejection2'))[,-1])\n        }\n    } else{\n        if(control){\n            return(melt(data[,unique(c(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('Dsg.Control.',1:sum(grepl('^Dsg.Control',names(data)))),paste0('offset.',1:N),paste0('Random.',1:N),paste0('U.',1:N),paste0('W.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N))),with=F],\n                        measure = list(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('Dsg.Control.',1:sum(grepl('^Dsg.Control',names(data)))),paste0('offset.',1:N),paste0('Random.',1:N),paste0('U.',1:N),paste0('W.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N)),\n                        value.name = c('ChIP','Dsg.Int','Dsg.Control','offset','Random','U','W','PostProb1','PostProb2','Rejection1','Rejection2'))[,-1])\n        } else{\n            return(melt(data[,unique(c(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('offset.',1:N),paste0('Random.',1:N),paste0('U.',1:N),paste0('W.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N))),with=F],\n                        measure = list(paste0('ChIP.',1:N),rep('Dsg.Int',N),paste0('offset.',1:N),paste0('Random.',1:N),paste0('U.',1:N),paste0('W.',1:N),rep('PostProb1',N),rep('PostProb2',N),rep('Rejection1',N),rep('Rejection2',N)),\n                        value.name = c('ChIP','Dsg.Int','offset','Random','U','W','PostProb1','PostProb2','Rejection1','Rejection2'))[,-1])\n        }\n    }\n}\n\nagg = function(data,data.unique,rows,agg,random=F){\n    data <- data.table::copy(data)\n    setkey(data,Group)\n\n    data.unique <- data.table::copy(data.unique)\n\n    # Filtering rows and aggregating\n    # This will give me the sum of weights per each Group (possible combination of ChIP, Control, etc.)\n    if(random==F){\n        data <- data[eval(parse(text=rows)),][,.(weights=sum(get(agg))),by=Group]\n    }\n    if(random==T){\n        data <- data[,.(AggPostProb1=sum(get(agg[1])),AggPostProb2=sum(get(agg[2]))),by=Group]\n    }\n\n    # Bringing the variables from data.unique into the aggregated data\n    # This will bring the variables back to the data\n    return(data.unique[data,on='Group'])\n\n    # return(data[eval(parse(text=rows)),][,.(weights=sum(get(agg))),by=eval(names(data)[!grepl('^PostProb|^JoinProb|^Rejection',names(data))])])\n}\n\ncreateOffset = function(ChIP,method='sum',span=1,plots=F,dirplot=NULL){\n    N = ncol(ChIP)\n    M = nrow(ChIP)\n    offset = matrix(NA,nrow=M,ncol=N)\n    if(method=='sum'){\n        offset = matrix(log(colSums(ChIP+1)),nrow=M,ncol=N,byrow=T)\n        return(offset)\n    }\n    if(method=='loess'){\n        log.ChIP = log(ChIP+1)\n        avg.ChIP = exp(rowMeans(log.ChIP)) #This is different than Love's approach, where widows with 0 counts are discarded in the geometric mean\n        log.avg.ChIP = log(avg.ChIP)\n\n        log.ChIP.M = log.ChIP - matrix(log.avg.ChIP,nrow=M,ncol=N,byrow = F) #M, from MA plot\n        log.ChIP.A = 0.5*(log.ChIP + matrix(log.avg.ChIP,nrow=M,ncol=N,byrow = F)) #A, from MA plot\n\n        # Calculating Loess\n        offset = sapply(1:N,function(i){limma::loessFit(y=log.ChIP.M[,i],x=log.ChIP.A[,i],span = span)$fitted})\n\n        #Plotting the results\n        if(plots){\n            for(i in 1:N){\n                o = order(log.ChIP.A[,i])\n\n                pdf(paste0(dirplot,'/Sample',i,'.pdf'))\n                smoothScatter(log.ChIP.M[,i]~log.ChIP.A[,i],main=paste0('Sample: ',i),xlab='Average',ylab='Minus')\n                abline(h=0,col='red',lwd=3)\n                lines(log.ChIP.A[o,i],offset[o,i],col='blue',lwd=3)\n                dev.off()\n            }\n        }\n        return(offset)\n    }\n    if(method=='ratio'){\n        log.ChIP = log(ChIP+1)\n        avg.ChIP = exp(rowMeans(log.ChIP)) #This is different than Love's approach, where widows with 0 counts are discarded in the geometric mean\n        log.avg.ChIP = log(avg.ChIP)\n\n        log.ChIP.M = log.ChIP - matrix(log.avg.ChIP,nrow=M,ncol=N,byrow = F) #M, from MA plot\n        log.ChIP.A = 0.5*(log.ChIP + matrix(log.avg.ChIP,nrow=M,ncol=N,byrow = F)) #A, from MA plot\n\n        # Calculating offset\n        medianRatio = apply(log.ChIP.M,2,median)\n        offset = matrix(medianRatio,nrow = M,ncol = N,byrow = T)\n\n        #Plotting the results\n        if(plots){\n            for(i in 1:N){\n                pdf(paste0(dirplot,'/Sample',i,'.pdf'))\n                smoothScatter(log.ChIP.M[,i]~log.ChIP.A[,i],main=paste0('Sample: ',i),xlab='Average',ylab='Minus')\n                abline(h=0,col='red',lwd=3)\n                abline(h=medianRatio[i],col='blue',lwd=3)\n                dev.off()\n            }\n        }\n        return(offset)\n    }\n}\n\nQ = function(P1,P2,loglik,pi,gamma){\n    return(sum(P1[1,]*log(pi))+sum(colSums(P1*loglik))+sum(colSums(P2[2:nrow(loglik),]%*%diag(log(c(t(gamma)))))))\n}\n\nglm.nb = function(par,Y.vec,X.mat,offset.vec,weights.vec){\n    l = dnbinom(Y.vec,mu=exp(X.mat%*%par[1:ncol(X.mat)]+offset.vec),size=1/par[length(par)],log=T);l[is.infinite(l)] = log(1e-300)\n    return(-sum(weights.vec*l))\n}\n\nderiv.nb = function(par,Y.vec,X.mat,offset.vec,weights.vec,...){\n    mu.vec = exp(X.mat%*%par[1:ncol(X.mat)]+offset.vec)\n    phi = par[length(par)]\n    return(-c(colSums(as.numeric(weights.vec)*as.numeric((Y.vec-mu.vec)/(1+phi*mu.vec))*X.mat),sum(as.numeric(weights.vec)*(log(1+phi*mu.vec)+phi*(Y.vec-mu.vec)/(1+phi*mu.vec)-digamma(Y.vec+1/phi)+digamma(1/phi))/(phi^2))))\n}\n\ninv.par = function(par,model){\n    if(model=='nb'){return(c(par[1:(length(par)-1)],1/par[length(par)]))}\n    if(model=='zinb'){\n        n = length(par)\n        return(c(par[1:((n-1)/2)],1/par[(n-1)/2+1],par[((n-1)/2+2):n]))}\n}\n\nHMM.chain = function(z,K){\n    if(max(z)>(K-1)){z=round((K-1)*(z-max(z))/(max(z)-min(z))+(K-1))}\n    MC = matrix(z,nrow = 1,ncol=length(z))\n    MC = table(c(MC[,-ncol(MC)]),c(MC[,-1]))\n    MC = as.matrix(MC/rowSums(MC))\n    MC = matrix(MC,ncol=ncol(MC),nrow=nrow(MC),byrow=F)\n    MC = check.prob(MC)\n    # for(i in 1:ncol(MC))\n    # {\n    #     MC[i,ncol(MC)] = 1-sum(MC[i,1:(ncol(MC)-1)])\n    #     MC[i,ncol(MC)] = ifelse(MC[i,ncol(MC)]>=1,1-epsilon.0,ifelse(MC[i,ncol(MC)]<=0,epsilon.0,MC[i,ncol(MC)]))\n    # }\n    return(MC)\n}\n\nHMM.mean = function(X.mat,offset.vec,psi,N,M,min.zero=min.zero,U=NULL,random=NULL){\n    K=nrow(psi)\n    mu = matrix(0,nrow=M,ncol=N*K)\n    for(k in 1:K){\n        mu[,k+0:(N-1)*K] = matrix(exp(X.mat%*%psi[k,]+offset.vec),nrow=M,ncol=N,byrow=F)\n    }\n    if(sum(mu==0)>0){mu[mu==0] = min.zero}\n    return(mu)\n}\n\nHMM.LL = function(Y.vec,mu,N,M,K,model,disp=NULL,zeroinfl=NULL,min.zero=.Machine$double.xmin){\n    LL = matrix(0,nrow=M,ncol=K)\n    # if(model=='poisson'){\n    #     for(k in 1:K){\n    #         LL[,k] = rowSums(matrix((dpois(Y.vec,lambda=c(mu[,k+0:(N-1)*K]),log=T)),nrow=M,ncol=N,byrow=F))\n    #     }\n    #\n    #     LL[exp(LL)==0] = log(min.zero)\n    #     return(LL)\n    # }\n    if(model=='nb'){\n        for(k in 1:K){\n            LL[,k] = rowSums(matrix((dnbinom(Y.vec,mu=c(mu[,k+0:(N-1)*K]),size=disp[k],log=T)),nrow=M,ncol=N,byrow=F))\n        }\n        LL[is.infinite(LL)] = log(min.zero)\n        # LL[exp(LL)==0] = log(min.zero)\n        return(LL)\n    }\n    # if(model=='zip'){\n    #     Yvec0 = 1*(Y.vec==0)\n    #     Zvec = c(zeroinfl)\n    #\n    #     #LL from Background\n    #     LogLik00 = dpois(0,lambda=c(mu[,1+0:(N-1)*K]),log=T);LogLik00[is.infinite(LogLik00)] = log(1e-300)\n    #     LogLik01 = dpois(Y.vec,lambda=c(mu[,1+0:(N-1)*K]),log=T);LogLik01[is.infinite(LogLik01)] = log(1e-300)\n    #     LL[,1] = rowSums(matrix((Yvec0)*log(Zvec + exp(log(1-Zvec)+LogLik00)) + (1-Yvec0)*(log(1-Zvec) + LogLik01),nrow=M,ncol=N,byrow=F))\n    #     LL[is.infinite(LL[,1]),1] = log(1e-300)\n    #     #LL from Differential\n    #     LL[,2] = rowSums(matrix((dpois(Y.vec,lambda=c(mu[,2+0:(N-1)*K]),log=T)),nrow=M,ncol=N,byrow=F))\n    #     #LL from Enrichment\n    #     LL[,K] = rowSums(matrix((dpois(Y.vec,lambda=c(mu[,K+0:(N-1)*K]),log=T)),nrow=M,ncol=N,byrow=F))\n    #\n    #     LL[exp(LL)==0] = log(min.zero)\n    #     return(LL)\n    # }\n    if(model=='zinb'){\n        Yvec0 = 1*(Y.vec==0)\n        Zvec = c(zeroinfl)\n        # if(K==2){\n            #LL from Background\n            LogLik00 = dnbinom(0,mu=c(mu[,1+0:(N-1)*K]),size=disp[1],log=T);LogLik00[is.infinite(LogLik00)] = log(min.zero)\n            LogLik01 = dnbinom(Y.vec,mu=c(mu[,1+0:(N-1)*K]),size=disp[1],log=T);LogLik01[is.infinite(LogLik01)] = log(min.zero)\n            LL[,1] = rowSums(matrix((Yvec0)*log(Zvec + exp(log(1-Zvec)+LogLik00)) + (1-Yvec0)*(log(1-Zvec) + LogLik01),nrow=M,ncol=N,byrow=F))\n            LL[is.infinite(LL[,1]),1] = log(min.zero)\n\n            #LL from Enrichment\n            LL[,K] = rowSums(matrix((dnbinom(Y.vec,mu=c(mu[,K+0:(N-1)*K]),size=disp[K],log=T)),nrow=M,ncol=N,byrow=F))\n            LL[is.infinite(LL[,K]),K] = log(min.zero)\n\n            # LL[exp(LL)==0] = log(min.zero)\n            return(LL)\n        # }\n        # if(K==3){\n        #     #LL from Background\n        #     LogLik00 = dnbinom(0,mu=c(mu[,1+0:(N-1)*K]),size=disp[1],log=T);LogLik00[is.infinite(LogLik00)] = log(1e-300)\n        #     LogLik01 = dnbinom(Y.vec,mu=c(mu[,1+0:(N-1)*K]),size=disp[1],log=T);LogLik01[is.infinite(LogLik01)] = log(1e-300)\n        #     LL[,1] = rowSums(matrix((Yvec0)*log(Zvec + exp(log(1-Zvec)+LogLik00)) + (1-Yvec0)*(log(1-Zvec) + LogLik01),nrow=M,ncol=N,byrow=F))\n        #     LL[is.infinite(LL[,1]),1] = log(1e-300)\n        #     #LL from Differential\n        #     LL[,2] = rowSums(matrix((dnbinom(Y.vec,mu=c(mu[,2+0:(N-1)*K]),size=disp[2],log=T)),nrow=M,ncol=N,byrow=F))\n        #     #LL from Enrichment\n        #     LL[,K] = rowSums(matrix((dnbinom(Y.vec,mu=c(mu[,K+0:(N-1)*K]),size=disp[K],log=T)),nrow=M,ncol=N,byrow=F))\n        #\n        #     LL[exp(LL)==0] = log(min.zero)\n        #     return(LL)\n        # }\n    }\n}\n\ncheck.prob = function(P){\n    # K=ncol(P);M=nrow(P)\n    # for(k in 1:K){\n    #     P[,k] = pmax(pmin(P[,k],1),0)\n    # }\n    # if(K==2){P[,K] = 1 - P[,1]}\n    # if(K>2){P[,K] = 1 - rowSums(P[,1:(K-1)])}\n    # P = P/matrix(rowSums(P),nrow=M,ncol=K,byrow=F)\n    P = pmax(pmin(P,1),0)\n    return(P/rowSums(P))\n}\n\nHMM.prob = function(dt){\n    # K=ncol(P1)\n    # #Adjusting Initial Probabilities\n    # pi=NULL\n    # for(i in 1:(K-1)){\n    #     assign(paste0('pi',i),ifelse(P1[1,i]>=1,1-epsilon.0,ifelse(P1[1,i]<=0,epsilon.0,P1[1,i])))\n    #     pi = c(pi,get(paste0('pi',i)))\n    # }\n    # assign(paste0('pi',K),1-sum(pi))\n    # assign(paste0('pi',K),ifelse(get(paste0('pi',K))>=1,1-epsilon.0,ifelse(get(paste0('pi',K))<=0,epsilon.0,get(paste0('pi',K)))))\n    # pi = c(pi,get(paste0('pi',K)))\n    pi <- dt[1,c(PostProb1,PostProb2)]\n    gamma <- unname(check.prob(as.matrix(t(dt[,.(c(sum(JoinProb11,na.rm=T),sum(JoinProb12,na.rm=T))/sum(JoinProb11+JoinProb12,na.rm=T),\n                                                c(sum(JoinProb21,na.rm=T),sum(JoinProb22,na.rm=T))/sum(JoinProb21+JoinProb22,na.rm=T))]))))\n\n    # #Adjusting Transition Probabilities\n    # gamma = matrix(0,nrow=K,ncol=K)\n    # for(i in 1:K){\n    #     idx = i*K-(K-1):0\n    #     aux.gamma=NULL\n    #     for(j in 1:(K-1)){\n    #         assign(paste0('gamma',i,j),sum(P2[,idx[j]],na.rm=T)/sum(P2[,idx],na.rm=T))\n    #         aux.gamma = c(aux.gamma,get(paste0('gamma',i,j)))\n    #     }\n    #     assign(paste0('gamma',i,K),1-sum(aux.gamma))\n    #     assign(paste0('gamma',i,K),ifelse(get(paste0('gamma',i,K))>=1,1-epsilon.0,ifelse(get(paste0('gamma',i,K))<=0,epsilon.0,get(paste0('gamma',i,K)))))\n    #     aux.gamma = c(aux.gamma,get(paste0('gamma',i,K)))\n    #     gamma[i,] = aux.gamma\n    # }\n    return(list('pi'=pi,'gamma'=gamma))\n}\n\nglm.zinb = function(par,Y.vec,X.mat,offset.vec,weights.vec){\n    mu.vec = exp(X.mat%*%par[1:ncol(X.mat)]+offset.vec)\n    zeroinfl.vec = 1/(1+exp(-(X.mat%*%par[(ncol(X.mat)+2):(2*ncol(X.mat)+1)]+offset.vec)))\n    idx.Y0=(Y.vec==0)\n\n    l0 = suppressWarnings(dnbinom(0,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l0[is.infinite(l0)] = log(1e-300)\n    l1 = suppressWarnings(dnbinom(Y.vec,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l1[is.infinite(l1)] = log(1e-300)\n\n    Loglik = weights.vec*(idx.Y0*log(zeroinfl.vec+exp(log(1-zeroinfl.vec)+l0))+(1-idx.Y0)*(log(1-zeroinfl.vec)+l1))\n\n    return(-sum(Loglik))\n}\n\nderiv.glm.zinb = function(par,Y.vec,X.mat,offset.vec,weights.vec){\n    # This function is correct (Checked with grad() from NumDeriv on 11/03/18)\n    mu.vec = exp(X.mat%*%par[1:ncol(X.mat)]+offset.vec)\n    zeroinfl.vec = 1/(1+exp(-(X.mat%*%par[(ncol(X.mat)+2):(2*ncol(X.mat)+1)]+offset.vec)))\n    idx.Y0=(Y.vec==0)\n\n    l0 = suppressWarnings(dnbinom(0,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l0[is.infinite(l0)] = log(1e-300)\n    l1 = suppressWarnings(dnbinom(Y.vec,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l1[is.infinite(l1)] = log(1e-300)\n\n    P0 = zeroinfl.vec+exp(log(1-zeroinfl.vec)+l0)\n    P1 = exp(log(1-zeroinfl.vec)+l1)\n\n    phi = par[(ncol(X.mat)+1)]\n    aux = (1+phi*mu.vec)\n\n    return(c(-colSums(as.numeric((idx.Y0)*(weights.vec/P0)*(1-zeroinfl.vec)*(-mu.vec*((1+phi*mu.vec)^(-(1/phi+1)))))*X.mat+as.numeric((1-idx.Y0)*(weights.vec/P1)*(1-zeroinfl.vec)*exp(l1)*(Y.vec-mu.vec)/(1+phi*mu.vec))*X.mat),\n             -sum((idx.Y0)*(weights.vec/P0)*(1-zeroinfl.vec)*(aux^(-1/phi))*(log(aux)/((phi)^2)-mu.vec/(phi*aux))+(1-idx.Y0)*(weights.vec/P1)*(1-zeroinfl.vec)*exp(l1)*(log(aux)/(phi^2)-mu.vec*(Y.vec+1/phi)/aux-digamma(Y.vec+1/phi)/(phi^2)+digamma(1/phi)/(phi^2)+Y.vec/phi)),\n             -colSums(as.numeric((idx.Y0)*(weights.vec/P0)*(1-exp(l0))*zeroinfl.vec*(1-zeroinfl.vec))*X.mat+as.numeric((1-idx.Y0)*(weights.vec/P1)*(-exp(l1))*zeroinfl.vec*(1-zeroinfl.vec))*X.mat)))\n}\n\nglmm.zinb = function(par,Y.vec,X.mat,offset.glm.vec,offset.zi.vec,weights.vec){\n    mu.vec = exp(X.mat%*%par[1:ncol(X.mat)]+offset.glm.vec)\n    zeroinfl.vec = 1/(1+exp(-(X.mat%*%par[(ncol(X.mat)+2):(2*ncol(X.mat)+1)]+offset.zi.vec)))\n    idx.Y0=(Y.vec==0)\n\n    l0 = suppressWarnings(dnbinom(0,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l0[is.infinite(l0)] = log(1e-300)\n    l1 = suppressWarnings(dnbinom(Y.vec,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l1[is.infinite(l1)] = log(1e-300)\n\n    Loglik = weights.vec*(idx.Y0*log(zeroinfl.vec+exp(log(1-zeroinfl.vec)+l0))+(1-idx.Y0)*(log(1-zeroinfl.vec)+l1))\n\n    return(-sum(Loglik))\n}\n\nderiv.glmm.zinb = function(par,Y.vec,X.mat,offset.glm.vec,offset.zi.vec,weights.vec){\n    mu.vec = exp(X.mat%*%par[1:ncol(X.mat)]+offset.glm.vec)\n    zeroinfl.vec = 1/(1+exp(-(X.mat%*%par[(ncol(X.mat)+2):(2*ncol(X.mat)+1)]+offset.zi.vec)))\n    idx.Y0=(Y.vec==0)\n\n    l0 = suppressWarnings(dnbinom(0,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l0[is.infinite(l0)] = log(1e-300)\n    l1 = suppressWarnings(dnbinom(Y.vec,mu=mu.vec,size=1/par[(ncol(X.mat)+1)],log=T));l1[is.infinite(l1)] = log(1e-300)\n\n    P0 = zeroinfl.vec+exp(log(1-zeroinfl.vec)+l0)\n    P1 = exp(log(1-zeroinfl.vec)+l1)\n\n    phi = par[(ncol(X.mat)+1)]\n    aux = (1+phi*mu.vec)\n\n    return(c(-colSums(as.numeric((idx.Y0)*(weights.vec/P0)*(1-zeroinfl.vec)*(-mu.vec*((1+phi*mu.vec)^(-(1/phi+1)))))*X.mat+as.numeric((1-idx.Y0)*(weights.vec/P1)*(1-zeroinfl.vec)*exp(l1)*(Y.vec-mu.vec)/(1+phi*mu.vec))*X.mat),\n             -sum((idx.Y0)*(weights.vec/P0)*(1-zeroinfl.vec)*(aux^(-1/phi))*(log(aux)/((phi)^2)-mu.vec/(phi*aux))+(1-idx.Y0)*(weights.vec/P1)*(1-zeroinfl.vec)*exp(l1)*(log(aux)/(phi^2)-mu.vec*(Y.vec+1/phi)/aux-digamma(Y.vec+1/phi)/(phi^2)+digamma(1/phi)/(phi^2)+Y.vec/phi)),\n             -colSums(as.numeric((idx.Y0)*(weights.vec/P0)*(1-exp(l0))*zeroinfl.vec*(1-zeroinfl.vec))*X.mat+as.numeric((1-idx.Y0)*(weights.vec/P1)*(-exp(l1))*zeroinfl.vec*(1-zeroinfl.vec))*X.mat)))\n}\n\nHMM.zeroinfl = function(csi,X.mat,offset.vec,N,M){\n    Z = matrix(1/(1+exp(-(X.mat%*%csi+offset.vec))),nrow=M,ncol=N)\n    return(Z)\n}\n\nglm.s2 = function(par,\n                  Yvec,Xmat,Uvec,Wvec,PostProbBackground,PostProbEnrichment,Offset,\n                  BackgroundPar,EnrichmentPar,min.zero=.Machine$double.xmin){\n    ### Zero indicator to be used in the ZINB model\n    Yvec0 = 1*(Yvec==0)\n    ### ZI model\n    zeroinfl.vec = 1/(1+exp(-(Xmat%*%BackgroundPar[(ncol(Xmat)+2):(2*ncol(Xmat)+1)]+Offset)))\n\n    ### Mean vectors\n    mu0 = exp(Xmat%*%BackgroundPar[1:ncol(Xmat)]+sqrt(1/par)*Uvec*Wvec+Offset)\n    mu1 = exp(Xmat%*%EnrichmentPar[1:ncol(Xmat)]+sqrt(1/par)*Uvec*Wvec+Offset)\n\n    ### Background log-likelihood\n    f00 = suppressWarnings(dnbinom(0,mu=mu0,size=BackgroundPar[(ncol(Xmat)+1)],log=F));f00[f00==0] = min.zero\n    f01 = suppressWarnings(dnbinom(Yvec,mu=mu0,size=BackgroundPar[(ncol(Xmat)+1)],log=F));f01[f01==0] = min.zero\n    f0 = log(Yvec0*(zeroinfl.vec+(1-zeroinfl.vec)*f00) + (1-Yvec0)*((1-zeroinfl.vec)*f01));f0[is.infinite(f0)] = log(min.zero)\n\n    ### Enrichment log-likelihood\n    f1 = suppressWarnings(dnbinom(Yvec,mu=mu1,size=EnrichmentPar[(ncol(Xmat)+1)],log=T));f1[is.infinite(f1)] = log(min.zero)\n\n    return(-sum(PostProbBackground*f0)-sum(PostProbEnrichment*f1))\n}\n\nHMM.init = function(ChIP.init,Control.init,offset.init,pcut,epsilon.em=1e-3,maxit.em=5,minit.em=3,gap.em=3,maxcount.em=3,max.phi=1e3,min.zero=.Machine$double.xmin,quant=0.75,quiet=T){\n    # Making data.table copies\n    ChIP.init <- data.table::copy(ChIP.init)\n    Control.init <- data.table::copy(Control.init)\n    offset.init <- data.table::copy(offset.init)\n\n    # General parameters\n    M=length(ChIP.init);N=1;K=2\n    error.em=1\n    it.em = 0\n    count.em = 0\n    parlist = list()\n\n    # Transforming data into data.table and calculating scores\n    if(is.null(Control.init)){\n        dt <- data.table(ChIP = ChIP.init,Dsg.Int = 1,offset = offset.init,PostProb1 = 1,PostProb2 = 1,JoinProb11 = 1,JoinProb12 = 1,JoinProb21 = 1,JoinProb22 = 1)\n        Score = dt[,scale(log(ChIP+1))]\n        ncolControl = 1\n        namesControl = gsub('Dsg.','',names(dt)[grepl('Dsg',names(dt))])\n\n        # Creating Aggragating Variable\n        dt[,Group := .GRP,by=c('ChIP','Dsg.Int','offset')]\n\n        # Creating Unique data.table\n        dt.unique <- unique(dt,by='Group')[,c('ChIP','Dsg.Int','offset','Group')]\n        setkey(dt.unique,Group)\n    } else{\n        dt <- data.table(ChIP = ChIP.init,Dsg.Int = 1,Dsg.Control = Control.init,offset = offset.init,PostProb1 = 1,PostProb2 = 1,JoinProb11 = 1,JoinProb12 = 1,JoinProb21 = 1,JoinProb22 = 1)\n        Score = dt[,scale(log(ChIP+1)-Dsg.Control)]\n        ncolControl = 2\n        namesControl = gsub('Dsg.','',names(dt)[grepl('Dsg',names(dt))])\n\n        # Creating Aggragating Variable\n        dt[,Group := .GRP,by=c('ChIP','Dsg.Int','Dsg.Control','offset')]\n\n        # Creating Unique data.table\n        dt.unique <- unique(dt,by='Group')[,c('ChIP','Dsg.Int','Dsg.Control','offset','Group')]\n        setkey(dt.unique,Group)\n    }\n\n    # Parameter initializations\n    ## Hiden States\n    dt[,z := as.numeric(cut(Score,breaks=c(-Inf,quantile(Score,quant),Inf)))]\n\n    ##Initial probabilities\n    pi1.old = 0.99;pi2.old = 1 - pi1.old;pi.old = c(pi1.old,pi2.old)\n\n    ## Slope and Intercept of each component\n    ### Aggregating data\n    dt1 <- agg(data = dt,data.unique = dt.unique,rows = '(z==1)',agg = 'PostProb1')\n    dt2 <- agg(data = dt,data.unique = dt.unique,rows = '(z==2)',agg = 'PostProb2')\n\n    ### Calculating MLEs\n    tryCatch({assign('model1i',optim(par=c(rep(0.25,ncolControl),1),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                     Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.vec=dt1[,offset],weights.vec=dt1[,weights]))},\n             error=function(e){model1i<<-list();model1i[['par']]<<-c(rep(0.25,ncolControl),1)})\n    tryCatch({assign('model2i',optim(par=c(rep(1,ncolControl),1),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                     Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=dt2[,offset],weights.vec=dt2[,weights]))},\n             error=function(e){model2i<<-list();model2i[['par']]<<-c(rep(1,ncolControl),1)})\n\n    rm(dt1);rm(dt2)\n\n    ### Saving parameters\n    psi1.old = inv.par(model1i$par,model='nb');psi2.old = inv.par(model2i$par,model='nb');psi.old = c(psi1.old,psi2.old)\n\n    ## Transition probabilities\n    gamma.old = HMM.chain(dt[,z],K)\n\n    # Putting all together\n    theta.old = c(pi.old,gamma.old,psi.old)\n    theta.k = theta.old\n    names(theta.k) = c(paste0('pi',1:K),paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx)),\n                       paste0('HMM1.',c(namesControl,'Disp')),paste0('HMM2.',c(namesControl,'Disp')))\n\n    # EM algorithm begins\n    while(count.em<maxcount.em & it.em<=maxit.em){\n        it.em = it.em + 1\n\n        # Updating parameters\n        pi.k = theta.k[paste0('pi',1:K)]\n        gamma.k = matrix(theta.k[paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx))],nrow=K,ncol=K,byrow=F);k=(K+1);for(i in 1:K){for(j in 1:K){assign(paste0('gamma',j,i,'.k'),theta.k[k]);k=k+1}}\n        psi1.k = theta.k[paste0('HMM1.',c(namesControl,'Disp'))]\n        psi2.k = theta.k[paste0('HMM2.',c(namesControl,'Disp'))]\n\n        # E-step\n        mu <- HMM.mean(X.mat=as.matrix(dt[,grepl('Dsg',names(dt)),with=F]),offset.vec=dt[,offset],psi=rbind(psi1.k,psi2.k)[,1:ncolControl],N=N,M=M)\n        loglik <- HMM.LL(Y.vec=dt[,ChIP],mu=mu,disp=rbind(psi1.k,psi2.k)[,(ncolControl+1)],N=N,M=M,K=K,model='nb')\n\n        # Forward-Backward probabilities\n        logF <- hmm_logF(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n        logB <- hmm_logB(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n\n        # Posterior probabilities\n        dt[,paste0('PostProb',1:2):=as.data.table(check.prob(hmm_P1(logF=logF,logB=logB)))]\n        dt[,paste0('JoinProb',c('11','12','21','22')):=as.data.table(check.prob(hmm_P2(logF=logF,logB=logB,logf1=loglik[,1],logf2=loglik[,2],gamma=gamma.k)))]\n\n        # M-step\n        ## Initial and transition probabilities\n        PostProb = HMM.prob(dt = dt)\n        pi.k1 = PostProb$pi\n        gamma.k1 = PostProb$gamma\n\n        ## Model parameters\n        ### Aggregating data\n        rejection = (pcut>0)*ifelse((0.9^it.em)>=pcut,(0.9^it.em),pcut)\n        dt1 <- agg(dt[,Rejection1 := PostProb1][PostProb1<rejection,Rejection1 := rbinom(.N,1,prob=PostProb1/rejection)*rejection],data.unique = dt.unique,rows = '(Rejection1>0)',agg = 'Rejection1')\n        dt2 <- agg(dt[,Rejection2 := PostProb2][PostProb2<rejection,Rejection2 := rbinom(.N,1,prob=PostProb2/rejection)*rejection],data.unique = dt.unique,rows = '(Rejection2>0)',agg = 'Rejection2')\n\n        ### Calculating MLEs\n        tryCatch({assign('model1',optim(par=inv.par(psi1.k,model='nb'),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                        Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.vec=dt1[,offset],weights.vec=dt1[,weights]))},\n                 error=function(e){model1<<-list();model1[['par']]<<-inv.par(psi1.k,model='nb');model1[['convergence']]<<-99})\n        tryCatch({assign('model2',optim(par=inv.par(psi2.k,model='nb'),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                        Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=dt2[,offset],weights.vec=dt2[,weights]))},\n                 error=function(e){model2<<-list();model2[['par']]<<-inv.par(psi2.k,model='nb');model2[['convergence']]<<-99})\n\n        rm(dt1);rm(dt2)\n\n        ### Saving parameters\n        psi1.k1 = inv.par(model1$par,model='nb')\n        psi2.k1 = inv.par(model2$par,model='nb')\n        psi.k1 = c(psi1.k1,psi2.k1)\n\n        # Updating parameter history\n        theta.k1 = c(pi.k1,gamma.k1,psi.k1)\n        names(theta.k1) = names(theta.k)\n        theta.k = theta.k1\n        parlist[[it.em]] = c(it=it.em,error=error.em,theta.k1,m1=model1$convergence,m2=model2$convergence)\n\n        # Computing EM error\n        gap = ifelse(it.em>minit.em,gap.em,1)\n        if(it.em>1){\n            parlist.old = parlist[[(it.em-gap)]][names(psi.k1)]\n            parlist.new = parlist[[it.em]][names(psi.k1)]\n        } else{\n            parlist.old = rep(1,length(names(psi.k1)))\n            parlist.new = rep(1,length(names(psi.k1)))\n        }\n        MRCPE = max(abs((parlist.new-parlist.old)/parlist.old)) #Max. Abs. Rel. Change. of par. estimates\n        error.em = ifelse(it.em>=2,MRCPE,1)\n        count.em = as.numeric(any(error.em<=epsilon.em))*(it.em>minit.em)*(count.em+1) + 0\n    }\n\n    # Organizing output\n    z = Viterbi(LOGF=loglik,P=pi.k1,GAMMA=gamma.k1)\n    logF <- setnames(as.data.table(logF),c('Background','Enrichment'))\n    logB <- setnames(as.data.table(logB),c('Background','Enrichment'))\n    loglik <- setnames(as.data.table(loglik),c('Background','Enrichment'))\n    mu <- as.data.table(mu)\n    return(list('Pi'=pi.k1,'Gamma'=gamma.k1,'Psi'=psi.k1,'Prob'=dt[,.(PostProb1,PostProb2)],\n                'LogF'=logF,'LogB'=logB,'Loglik'=loglik,'Parhist'=as.data.table(do.call(rbind,parlist)),'Mean'=mu,'Viterbi'=z))\n}\n\nZIHMM = function(ChIP,Control,offset,control)\n{\n    # Creating control elements\n    for(i in seq_along(control)){assign(names(control)[i],control[[i]])}\n    if(!(length(epsilon.em)==4) & criterion=='MULTI'){stop('For MULTI criterion, the length of error.em must be 4.')}\n\n    # General parameters\n    M=nrow(ChIP);N=ncol(ChIP);K=2\n    error.em=1\n    it.em = 0\n    count.em = 0\n    parlist = list()\n    zlist = list()\n\n    # Transforming data into data.table\n    if(is.null(Control)){\n        DT = data.table(ChIP = ChIP,Dsg.Int = 1,offset = offset,PostProb1=1,PostProb2=1,JoinProb11=1,JoinProb12=1,JoinProb21=1,JoinProb22=1,Rejection1=1,Rejection2=1)\n        setnames(DT,c(paste0('ChIP.',1:N),'Dsg.Int',paste0('offset.',1:N),'PostProb1','PostProb2','JoinProb11','JoinProb12','JoinProb21','JoinProb22','Rejection1','Rejection2'))\n        ncolControl = 1\n        namesControl = c('Int')\n\n        # Stacking DT\n        DTvec <- vecData(DT,N,control = F)\n\n        # Creating Aggragating Variable\n        DTvec[,Group := .GRP,by=c('ChIP','Dsg.Int','offset')]\n\n        # Creating Unique data.table\n        DTvec.unique <- unique(DTvec,by='Group')[,c('ChIP','Dsg.Int','offset','Group')]\n        setkey(DTvec.unique,Group)\n    } else{\n        DT = data.table(ChIP = ChIP,Dsg.Int = 1,Dsg.Control = Control,offset = offset,PostProb1=1,PostProb2=1,JoinProb11=1,JoinProb12=1,JoinProb21=1,JoinProb22=1,Rejection1=1,Rejection2=1)\n        setnames(DT,c(paste0('ChIP.',1:N),'Dsg.Int',paste0('Dsg.Control.',1:N),paste0('offset.',1:N),'PostProb1','PostProb2','JoinProb11','JoinProb12','JoinProb21','JoinProb22','Rejection1','Rejection2'))\n        ncolControl = 2\n        namesControl = c('Int','Control')\n\n        # Stacking DT\n        DTvec <- vecData(DT,N)\n\n        # Creating Aggragating Variable\n        DTvec[,Group := .GRP,by=c('ChIP','Dsg.Int','Dsg.Control','offset')]\n\n        # Creating Unique data.table\n        DTvec.unique <- unique(DTvec,by='Group')[,c('ChIP','Dsg.Int','Dsg.Control','offset','Group')]\n        setkey(DTvec.unique,Group)\n    }\n\n    # Parameter initializations\n    if(!quiet){cat(paste0(c(rep('#',45),'\\n')));cat(\"Algorithm initialization...\\n\")}\n    if(is.null(Control)){\n        model.list = HMM.init(ChIP.init=DT[,rowSums(.SD),.SDcols = paste0('ChIP.',1:N)],\n                              Control=NULL,\n                              offset.init=DT[,rowMeans(.SD),.SDcols = paste0('offset.',1:N)],pcut=pcut)\n    } else{\n        model.list = HMM.init(ChIP.init=DT[,rowSums(.SD),.SDcols = paste0('ChIP.',1:N)],\n                              Control.init=DT[,rowMeans(.SD),.SDcols = paste0('Dsg.Control.',1:N)],\n                              offset.init=DT[,rowMeans(.SD),.SDcols = paste0('offset.',1:N)],pcut=pcut)\n    }\n    DT[,z := model.list$Viterbi]\n    DTvec[,z := rep(model.list$Viterbi,N)]\n\n    ## Initial probabilities\n    pi1.old = 0.99;pi2.old = 1 - pi1.old;pi.old = c(pi1.old,pi2.old)\n\n    ## Model-specific parameters\n    ### Aggregating data\n    dt1 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(z==0)',agg = 'PostProb1')\n    dt2 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(z==1)',agg = 'PostProb2')\n\n    ### Calculating MLEs\n    tryCatch({assign('psi1.old',inv.par(optim(par=c(rep(0.25,ncolControl),1),fn=glm.nb,gr=deriv.nb,\n                                              Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.vec=dt1[,offset],weights.vec=dt1[,weights],method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi))$par,model='nb')[c(1:ncolControl,(ncolControl+1),1:ncolControl)])},\n             error=function(e){psi1.old<<-inv.par(c(rep(0.25,ncolControl),1),model='nb')[c(1:ncolControl,(ncolControl+1),1:ncolControl)]})\n    tryCatch({assign('psi2.old',inv.par(optim(par=c(rep(1,ncolControl),1),fn=glm.nb,gr=deriv.nb,\n                                              Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=dt2[,offset],weights.vec=dt2[,weights],method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi))$par,model='nb'))},\n             error=function(e){psi2.old<<-inv.par(c(rep(1,ncolControl),1),model='nb')})\n\n    rm(dt1);rm(dt2)\n\n    ### Saving parameters\n    psi.old = c(psi1.old,psi2.old)\n\n    ## Transition probabilities\n    gamma.old = HMM.chain(DT[,z],K)\n\n    # Putting all together\n    theta.old = c(pi.old,gamma.old,psi.old)\n    theta.k = theta.old\n    names(theta.k) = c(paste0('pi',1:K),paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx)),\n                       c(paste0('HMM1.',c(namesControl,'Disp')),paste0('HMM1.ZI.',namesControl)),paste0('HMM2.',c(namesControl,'Disp')))\n\n    if(!quiet){cat(paste0(\"Initialization completed!\\n\"));cat(paste0(c(rep('#',45),'\\n')))}\n\n    # EM algorithm begins\n    if(!quiet){cat(\"EM algorithm begins...\\n\")}\n\n    while(count.em<maxcount.em & it.em<=maxit.em){\n        it.em = it.em+1\n\n        # Updating parameters\n        pi.k = theta.k[paste0('pi',1:K)]\n        gamma.k = matrix(theta.k[paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx))],nrow=K,ncol=K,byrow=F);k=(K+1);for(i in 1:K){for(j in 1:K){assign(paste0('gamma',j,i,'.k'),theta.k[k]);k=k+1}}\n        psi1.k = theta.k[c(paste0('HMM1.',c(namesControl,'Disp')),paste0('HMM1.ZI.',namesControl))]\n        psi2.k = theta.k[paste0('HMM2.',c(namesControl,'Disp'))]\n\n        # E-step\n        mu <- HMM.mean(X.mat=as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),offset.vec=DTvec[,offset],psi=rbind(psi1.k[1:ncolControl],psi2.k[1:ncolControl]),N=N,M=M)\n        zeroinfl <- HMM.zeroinfl(csi=psi1.k[(ncolControl+2):length(psi1.k)],X.mat=as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),offset.vec=DTvec[,offset],N=N,M=M)\n        loglik <- HMM.LL(Y.vec=DTvec[,ChIP],mu=mu,N=N,M=M,K=K,zeroinfl=zeroinfl,disp=c(psi1.k[ncolControl+1],psi2.k[ncolControl+1]),model='zinb')\n\n        # Forward-Backward probabilities\n        logF <- hmm_logF(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n        logB <- hmm_logB(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n\n        # Posterior probabilities\n        DT[,paste0('PostProb',1:2):=as.data.table(check.prob(hmm_P1(logF=logF,logB=logB)))]\n        DT[,paste0('JoinProb',c('11','12','21','22')):=as.data.table(check.prob(hmm_P2(logF=logF,logB=logB,logf1=loglik[,1],logf2=loglik[,2],gamma=gamma.k)))]\n\n        # M-step\n        ## Initial and transition probabilities\n        PostProb = HMM.prob(DT)\n        pi.k1 = PostProb$pi\n        gamma.k1 = PostProb$gamma\n        zlist[[it.em]] = Viterbi(LOGF=loglik,P=pi.k1,GAMMA=gamma.k1)\n\n        ## Model parameters\n        ### Updating posterior probabilities with rejection-controlled EM\n        rejection = (pcut>0)*ifelse((0.9^it.em)>=pcut,(0.9^it.em),pcut)\n        DT[,c('Rejection1','Rejection2') := list(PostProb1,PostProb2)]\n        DT[PostProb1<rejection,Rejection1 := rbinom(.N,1,prob=PostProb1/rejection)*rejection]\n        DT[PostProb2<rejection,Rejection2 := rbinom(.N,1,prob=PostProb2/rejection)*rejection]\n\n        ### Updating the vectorized dataset\n        DTvec[,c('Rejection1','Rejection2') := .(rep(DT[,Rejection1],N),rep(DT[,Rejection2],N))]\n\n        ### Aggregating data\n        dt1 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(Rejection1>0)',agg = 'Rejection1')\n        dt2 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(Rejection2>0)',agg = 'Rejection2')\n\n        ### Calculating MLEs\n        tryCatch({assign('model1',optim(par=inv.par(psi1.k,model='zinb'),fn=glm.zinb,gr = deriv.glm.zinb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi,rep(-Inf,ncolControl)),\n                                        Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.vec=dt1[,offset],weights.vec=dt1[,weights]))},\n                 error=function(e){model1<<-list();model1[['par']]<<-inv.par(psi1.k,model='zinb');model1[['convergence']]<<-99})\n        tryCatch({assign('model2',optim(par=inv.par(psi2.k,model='nb'),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                        Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=dt2[,offset],weights.vec=dt2[,weights]))},\n                     error=function(e){model2<<-list();model2[['par']]<<-inv.par(psi2.k,model='nb');model2[['convergence']]<<-99})\n\n        rm(dt1);rm(dt2)\n\n        ### Saving parameters\n        psi1.k1 = inv.par(model1$par,model='zinb');names(psi1.k1) = names(psi1.k)\n        psi2.k1 = inv.par(model2$par,model='nb')\n        psi.k1 = c(psi1.k1,psi2.k1)\n\n        # Updating parameter history\n        theta.k1 = c(pi.k1,gamma.k1,psi.k1)\n        names(theta.k1) = names(theta.k)\n        theta.k = theta.k1\n        parlist[[it.em]] = c(it=it.em,Q=Q(as.matrix(DT[,.(PostProb1,PostProb2)]),as.matrix(DT[,.(JoinProb11,JoinProb12,JoinProb21,JoinProb22)]),loglik,pi.k1,gamma.k1),\n                             error=error.em[1],theta.k1,m1=model1$convergence,m2=model2$convergence)\n\n        # Computing EM error\n        gap = ifelse(it.em>minit.em,gap.em,1)\n        if(it.em>1){\n            parlist.old = parlist[[(it.em-gap)]][names(psi.k1)]\n            parlist.new = parlist[[it.em]][names(psi.k1)]\n            zlist.table = data.table(old = zlist[[(it.em-gap)]], new = zlist[[it.em]])\n            ACC = 100*zlist.table[,.N,by=.(old,new)][(old==0 & new==0) | (old==1 & new==1),sum(N)]/M\n        } else{\n            parlist.old = rep(1,length(names(psi.k1)))\n            parlist.new = rep(1,length(names(psi.k1)))\n            ACC = 0\n        }\n\n        MRCPE = max(abs((parlist.new-parlist.old)/parlist.old)) #Max. Abs. Rel. Change. of par. estimates\n        MACPE = max(abs(parlist.new-parlist.old)) #Max. Abs. Change. of par. estimates\n        ARCEL = ifelse(it.em>=2,abs((parlist[[it.em]][['Q']] - parlist[[(it.em-gap)]][['Q']])/parlist[[(it.em-gap)]][['Q']]),0) #Abs. Rel. Change of expected log-likelihood of complete data (Q function)\n        MULTI = c(MRCPE,MACPE,ARCEL,100-ACC)\n        error.em = (it.em>=2)*get(criterion) + (it.em<2)*rep(1,length(get(criterion)))\n        count.em = as.numeric(any(error.em<=epsilon.em))*(it.em>minit.em)*(count.em+1) + 0\n\n        #Outputing history\n        if(!quiet){\n            cat(paste0(c(rep('#',45),'\\n')))\n            cat('\\rIteration: ',it.em,', Error(s): ',paste(formatC(error.em, format = \"e\", digits = 2),collapse = ', '),', Viterbi Agreement: ',round(ACC,2),'%.\\n',sep='')\n            cat(\"\\r\",paste('Q-function: '),parlist[[it.em]][['Q']],\"\\n\")\n            cat(\"\\r\",paste('Max. abs. rel. change of parameter estimates: '),MRCPE,\"\\n\")\n            cat(\"\\r\",paste('Max. abs. change of parameter estimates: '),MACPE,\"\\n\")\n            cat(\"\\r\",paste('Abs. rel. change of Q-function: '),ARCEL,\"\\n\")\n            cat(paste0(c(rep('#',45),'\\n')))\n        }\n    }\n\n    # Organizing output\n    logF <- setnames(as.data.table(logF),c('Background','Enrichment'))\n    logB <- setnames(as.data.table(logB),c('Background','Enrichment'))\n    loglik <- setnames(as.data.table(loglik),c('Background','Enrichment'))\n    mu <- as.data.table(mu)\n\n    if(!quiet){cat('\\nDone!\\n')}\n    return(list('Pi'=pi.k1,'Gamma'=gamma.k1,'Psi'=psi.k1,'Prob'=DT[,.(PostProb1,PostProb2)],'LogF'=logF,'LogB'=logB,'Loglik'=loglik,'Parhist'=as.data.frame(do.call(rbind,parlist)),\n                'Mean'=mu,'Viterbi'=zlist[[it.em]]))\n}\n\nZIMHMM = function(ChIP,Control,offset,random,control)\n{\n    # Creating control elements\n    for(i in seq_along(control)){assign(names(control)[i],control[[i]])}\n    if(!(length(epsilon.em)==4) & criterion=='MULTI'){stop('For MULTI criterion, the length of error.em must be 4.')}\n\n    # General parameters\n    M=nrow(ChIP);N=ncol(ChIP);K=2\n    error.em=1\n    it.em = 0\n    count.em = 0\n    parlist = list()\n    zlist = list()\n\n    # Transforming data into data.table\n    if(is.null(Control)){\n        DT = data.table(ChIP = ChIP,Dsg.Int = 1,offset = offset,PostProb1=1,PostProb2=1,JoinProb11=1,JoinProb12=1,JoinProb21=1,JoinProb22=1,Rejection1=1,Rejection2=1)\n        setnames(DT,c(paste0('ChIP.',1:N),'Dsg.Int',paste0('offset.',1:N),'PostProb1','PostProb2','JoinProb11','JoinProb12','JoinProb21','JoinProb22','Rejection1','Rejection2'))\n        ncolControl = 1\n        namesControl = c('Int')\n\n        # Creating covariate associated with the random component (sigma2*u*1 if intercept, sigma2*u*Control if slope)\n        ## Variance component and Latent vector of random effects\n        sigma2.old = 0.10\n        u.old = as.numeric(scale(colSums(log(ChIP+1))))\n\n        # Creating covariate associates with the random component (1 if intercept, Control if slope)\n        if(random=='intercept'){\n            DT[,paste0('Random.',1:N) := as.data.table(DT[,mapply(\"*\",sqrt(sigma2.old)*u.old,mget(rep('Dsg.Int',N)))])]\n            DT[,paste0('U.',1:N) := as.list(u.old)]\n            DT[,paste0('W.',1:N) := mget(rep('Dsg.Int',N))]\n        } else{\n            stop('Specify random=\"intercept\"')\n        }\n\n        # Stacking DT\n        DTvec <- vecData(DT,N,control = F,random = T)\n\n        # Creating Aggragating Variable\n        DTvec[,Group := .GRP,by=c('ChIP','Dsg.Int','offset','Random','U','W')]\n\n        # Creating Unique data.table\n        DTvec.unique <- unique(DTvec,by='Group')[,c('ChIP','Dsg.Int','offset','Random','U','W','Group')]\n        setkey(DTvec.unique,Group)\n    } else{\n        DT = data.table(ChIP = ChIP,Dsg.Int = 1,Dsg.Control = Control,offset = offset,PostProb1=1,PostProb2=1,JoinProb11=1,JoinProb12=1,JoinProb21=1,JoinProb22=1,Rejection1=1,Rejection2=1)\n        setnames(DT,c(paste0('ChIP.',1:N),'Dsg.Int',paste0('Dsg.Control.',1:N),paste0('offset.',1:N),'PostProb1','PostProb2','JoinProb11','JoinProb12','JoinProb21','JoinProb22','Rejection1','Rejection2'))\n        ncolControl = 2\n        namesControl = c('Int','Control')\n\n        # Creating covariate associated with the random component (sigma2*u*1 if intercept, sigma2*u*Control if slope)\n        ## Variance component and Latent vector of random effects\n        sigma2.old = 0.10\n        u.old = as.numeric(scale(colSums(log(ChIP+1))))\n\n        if(random=='intercept'){\n            DT[,paste0('Random.',1:N) := as.data.table(DT[,mapply(\"*\",sqrt(sigma2.old)*u.old,mget(rep('Dsg.Int',N)))])]\n            DT[,paste0('U.',1:N) := as.list(u.old)]\n            DT[,paste0('W.',1:N) := mget(rep('Dsg.Int',N))]\n        } else{\n            DT[,paste0('Random.',1:N) := as.data.table(DT[,mapply(\"*\",sqrt(sigma2.old)*u.old,mget(paste0('Dsg.Control.',1:N)))])]\n            DT[,paste0('U.',1:N) := as.list(u.old)]\n            DT[,paste0('W.',1:N) := mget(paste0('Dsg.Control.',1:N))]\n        }\n\n        # Stacking DT\n        DTvec <- vecData(DT,N,random = T)\n\n        # Creating Aggragating Variable\n        DTvec[,Group := .GRP,by=c('ChIP','Dsg.Int','Dsg.Control','offset','Random','U','W')]\n\n        # Creating Unique data.table\n        DTvec.unique <- unique(DTvec,by='Group')[,c('ChIP','Dsg.Int','Dsg.Control','offset','Random','U','W','Group')]\n        setkey(DTvec.unique,Group)\n    }\n\n    # Parameter initializations\n    if(!quiet){cat(paste0(c(rep('#',45),'\\n')));cat(\"Algorithm initialization...\\n\")}\n    if(is.null(Control)){\n        model.list = HMM.init(ChIP.init=DT[,rowSums(.SD),.SDcols = paste0('ChIP.',1:N)],\n                              Control=NULL,\n                              offset.init=DT[,rowMeans(.SD),.SDcols = paste0('offset.',1:N)],pcut=pcut)\n    } else{\n        model.list = HMM.init(ChIP.init=DT[,rowSums(.SD),.SDcols = paste0('ChIP.',1:N)],\n                              Control.init=DT[,rowMeans(.SD),.SDcols = paste0('Dsg.Control.',1:N)],\n                              offset.init=DT[,rowMeans(.SD),.SDcols = paste0('offset.',1:N)],pcut=pcut)\n    }\n    DT[,z := model.list$Viterbi]\n    DTvec[,z := rep(model.list$Viterbi,N)]\n\n    ## Initial probabilities\n    pi1.old = 0.99;pi2.old = 1 - pi1.old;pi.old = c(pi1.old,pi2.old)\n\n    ## Model-specific parameters\n    ### Aggregating data\n    dt1 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(z==0)',agg = 'PostProb1')\n    dt2 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(z==1)',agg = 'PostProb2')\n\n    ### Calculating MLEs\n    tryCatch({assign('psi1.old',inv.par(optim(par=c(rep(0.25,ncolControl),1),fn=glm.nb,gr=deriv.nb,\n                                              Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.vec=dt1[,offset],weights.vec=dt1[,weights],method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi))$par,model='nb')[c(1:ncolControl,(ncolControl+1),1:ncolControl)])},\n             error=function(e){psi1.old<<-inv.par(c(rep(0.25,ncolControl),1),model='nb')[c(1:ncolControl,(ncolControl+1),1:ncolControl)]})\n    tryCatch({assign('psi2.old',inv.par(optim(par=c(rep(1,ncolControl),1),fn=glm.nb,gr=deriv.nb,\n                                              Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=dt2[,offset],weights.vec=dt2[,weights],method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi))$par,model='nb'))},\n             error=function(e){psi2.old<<-inv.par(c(rep(1,ncolControl),1),model='nb')})\n\n    rm(dt1);rm(dt2)\n\n    ### Saving parameters\n    psi.old = c(psi1.old,psi2.old)\n\n    ## Transition probabilities\n    gamma.old = HMM.chain(DT[,z],K)\n\n    #Putting all together\n    theta.old = c(pi.old,gamma.old,psi.old,sigma2.old,u.old)\n    theta.k = theta.old\n    name.psi1 = c(paste0('HMM1.',c(namesControl,'Disp')),paste0('HMM1.ZI.',namesControl))\n    names(theta.k) = c(paste0('pi',1:K),paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx)),\n                       name.psi1,paste0('HMM2.',c(namesControl,'Disp')),'sigma2',paste0('U',1:N))\n\n    if(!quiet){cat(paste0(\"Initialization completed!\\n\"));cat(paste0(c(rep('#',45),'\\n')))}\n\n    #EM algorithm begins\n    if(!quiet){cat(\"EM algorithm begins...\\n\")}\n\n    while(count.em<maxcount.em & it.em<=maxit.em){\n        it.em = it.em+1\n\n        #Updating parameters\n        pi.k = theta.k[paste0('pi',1:K)]\n        gamma.k = matrix(theta.k[paste0('gamma',as.character(transform(expand.grid(1:K,1:K),idx=paste0(Var1,Var2))$idx))],nrow=K,ncol=K,byrow=F);k=(K+1);for(i in 1:K){for(j in 1:K){assign(paste0('gamma',j,i,'.k'),theta.k[k]);k=k+1}}\n        psi1.k = theta.k[c(paste0('HMM1.',c(namesControl,'Disp')),paste0('HMM1.ZI.',namesControl))]\n        psi2.k = theta.k[paste0('HMM2.',c(namesControl,'Disp'))]\n        sigma2.k = theta.k['sigma2']\n        u.k = theta.k[paste0('U',1:N)]\n\n        #E-step\n        zeroinfl <- HMM.zeroinfl(csi=psi1.k[(ncolControl+2):length(psi1.k)],X.mat=as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),offset.vec=DTvec[,offset],N=N,M=M)\n\n        ## Laplace Approximation: 'estimating' latent random effects\n        U.opt <- minqa::bobyqa(par = u.k,fn = function(x,...){-integrand(x,...)},\n                               YVEC=DTvec[,ChIP],XMAT=as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),\n                               BETA=matrix(c(psi1.k[1:ncolControl],psi2.k[1:ncolControl]),nrow=K,byrow=T),\n                               DISP=c(psi1.k[(ncolControl+1)],psi2.k[(ncolControl+1)]),P=pi.k,GAMMA=gamma.k,\n                               OFFSETVEC=DTvec[,offset],ZEROINFL=zeroinfl,\n                               W=DTvec[,W],SIGMA2=sigma2.k)\n        u.k1 = U.opt$par\n\n        ########################################################################\n        ## Updating DT and DTvec\n        if(random=='intercept'){\n            DT[,paste0('Random.',1:N) := as.data.table(DT[,mapply(\"*\",sqrt(sigma2.k)*u.k1,mget(rep('Dsg.Int',N)))])]\n            DT[,paste0('U.',1:N) := as.list(u.k1)]\n            DT[,paste0('W.',1:N) := mget(rep('Dsg.Int',N))]\n        } else{\n            DT[,paste0('Random.',1:N) := as.data.table(DT[,mapply(\"*\",sqrt(sigma2.k)*u.k1,mget(paste0('Dsg.Control.',1:N)))])]\n            DT[,paste0('U.',1:N) := as.list(u.k1)]\n            DT[,paste0('W.',1:N) := mget(paste0('Dsg.Control.',1:N))]\n        }\n\n        # Stacking DT\n        DTvec <- vecData(DT,N,random = T)\n\n        # Creating Aggragating Variable\n        DTvec[,Group := .GRP,by=c('ChIP','Dsg.Int','Dsg.Control','offset','Random','U','W')]\n\n        # Creating Unique data.table\n        DTvec.unique <- unique(DTvec,by='Group')[,c('ChIP','Dsg.Int','Dsg.Control','offset','Random','U','W','Group')]\n        setkey(DTvec.unique,Group)\n        ########################################################################\n\n        ## Mean and log-likelihood matrices\n        mu = MHMMmean(XMAT = as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),BETA = matrix(c(psi1.k[1:ncolControl],psi2.k[1:ncolControl]),nrow=K,byrow=T),RANDOM = as.matrix(DTvec[,Random]),OFFSETVEC = as.matrix(DTvec[,offset]),N = N,M = M,K = K)\n        mu[mu==0] = min.zero\n        loglik = MHMMLik(YVEC = DTvec[,ChIP],ZEROINFL = zeroinfl,MU = mu,DISP = c(psi1.k[(ncolControl+1)],psi2.k[(ncolControl+1)]),N = N,M = M,K = K)\n\n        # Forward-Backward probabilities\n        logF = hmm_logF(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n        logB = hmm_logB(logf1 = loglik[,1], logf2 = loglik[,2], pi = pi.k,gamma=gamma.k)\n\n        # Posterior probabilities\n        DT[,paste0('PostProb',1:2):=as.data.table(check.prob(hmm_P1(logF=logF,logB=logB)))]\n        DT[,paste0('JoinProb',c('11','12','21','22')):=as.data.table(check.prob(hmm_P2(logF=logF,logB=logB,logf1=loglik[,1],logf2=loglik[,2],gamma=gamma.k)))]\n\n        # M-step\n        ## Initial and transition probabilities\n        PostProb = HMM.prob(DT)\n        pi.k1 = PostProb$pi\n        gamma.k1 = PostProb$gamma\n        zlist[[it.em]] = Viterbi(LOGF=loglik,P=pi.k1,GAMMA=gamma.k1)\n\n        ## Model parameters\n        ### General parameters for conditional EM iterations\n        error.inner.em = 1\n        count.inner.em = 1\n        parhist.inner.em = data.frame()\n\n        ### Updating posterior probabilities with rejection-controlled EM\n        rejection = (pcut>0)*ifelse((0.9^it.em)>=pcut,(0.9^it.em),pcut)\n        DT[,c('Rejection1','Rejection2') := list(PostProb1,PostProb2)]\n        DT[PostProb1<rejection,Rejection1 := rbinom(.N,1,prob=PostProb1/rejection)*rejection]\n        DT[PostProb2<rejection,Rejection2 := rbinom(.N,1,prob=PostProb2/rejection)*rejection]\n\n        ### Updating the vectorized dataset\n        DTvec[,c('Rejection1','Rejection2') := .(rep(DT[,Rejection1],N),rep(DT[,Rejection2],N))]\n        DTvec[,c('PostProb1','PostProb2') := .(rep(DT[,PostProb1],N),rep(DT[,PostProb2],N))]\n\n        ### Aggregating data\n        dt1 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(Rejection1>0)',agg = 'Rejection1')\n        dt2 <- agg(data = DTvec,data.unique = DTvec.unique,rows = '(Rejection2>0)',agg = 'Rejection2')\n        dtsigma <- agg(data = DTvec,data.unique = DTvec.unique,agg = c('PostProb1','PostProb2'),random = T)\n\n        ### Conditional EM begins\n        while(error.inner.em>epsilon.inner.em & count.inner.em<=maxcount.inner.em){\n            tryCatch({assign('model1',optim(par = inv.par(psi1.k,'zinb'),fn = glmm.zinb,gr = deriv.glmm.zinb,method = 'L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi,rep(-Inf,ncolControl)),\n                                            Y.vec=dt1[,ChIP],X.mat=as.matrix(dt1[,grepl('Dsg',names(dt1)),with=F]),offset.glm.vec=as.matrix(dt1[,rowSums(.SD),.SDcols=c('Random','offset')]),offset.zi.vec=as.matrix(dt1[,offset]),weights.vec=as.matrix(dt1[,weights])))},\n                     error=function(e){model1<<-list();model1[['par']]<<-inv.par(psi1.k,'zinb');model1[['convergence']]<<-99})\n            tryCatch({assign('model2',optim(par=inv.par(psi2.k,model='nb'),fn=glm.nb,gr=deriv.nb,method='L-BFGS-B',lower=c(rep(-Inf,ncolControl),1/max.phi),\n                                            Y.vec=dt2[,ChIP],X.mat=as.matrix(dt2[,grepl('Dsg',names(dt2)),with=F]),offset.vec=as.matrix(dt2[,rowSums(.SD),.SDcols=c('Random','offset')]),weights.vec=as.matrix(dt2[,weights])))},\n                     error=function(e){model2<<-list();model2[['par']]<<-inv.par(psi2.k,model='nb');model2[['convergence']]<<-99})\n\n            psi1.k = inv.par(model1$par,model='zinb');names(psi1.k) = name.psi1\n            psi2.k = inv.par(model2$par,model='nb')\n\n            tryCatch({assign('model3',optim(par = 1/sigma2.old,fn = glm.s2,method = 'L-BFGS-B',lower = 1/max.sigma2,upper = 1/min.sigma2,\n                                            Yvec = dtsigma[,ChIP],Xmat = as.matrix(dtsigma[,grepl('Dsg',names(dtsigma)),with=F]),Uvec = dtsigma[,U],Wvec = dtsigma[,W],\n                                            PostProbBackground = dtsigma[,AggPostProb1],PostProbEnrichment = dtsigma[,AggPostProb2],Offset = dtsigma[,offset],\n                                            BackgroundPar = psi1.k,EnrichmentPar = psi2.k))},\n                     error=function(e){model3<<-list();model3[['par']]<<-1/sigma2.k;model3[['convergence']]<<-99})\n\n            sigma2.k = 1/model3$par\n\n            # Updating the aggregated data\n            dt1[,Random := sqrt(sigma2.k)*U]\n            dt2[,Random := sqrt(sigma2.k)*U]\n\n            # Updating inner parameters\n            parhist.inner.em = rbind(parhist.inner.em,data.frame(t(c(psi1.k,psi2.k,sigma2=sigma2.k))))\n\n            # Calculating inner error\n            if(count.inner.em>1){error.inner.em = max(abs((parhist.inner.em[count.inner.em,]-parhist.inner.em[(count.inner.em-1),])/parhist.inner.em[(count.inner.em-1),]))}\n            count.inner.em = count.inner.em + 1\n        }\n\n        # Updating parameter history\n        psi1.k1 = psi1.k;psi2.k1 = psi2.k;psi.k1 = c(psi1.k1,psi2.k1)\n        sigma2.k1 = sigma2.k\n        theta.k1 = c(pi.k1,gamma.k1,psi.k1,sigma2.k1,u.k1);names(theta.k1) = names(theta.k)\n        theta.k = theta.k1\n        parlist[[it.em]] = c(it=it.em,Q=Q(as.matrix(DT[,.(PostProb1,PostProb2)]),as.matrix(DT[,.(JoinProb11,JoinProb12,JoinProb21,JoinProb22)]),loglik,pi.k1,gamma.k1),\n                             error=error.em[1],theta.k1,m1=model1$convergence,m2=model2$convergence,m3=model3$convergence)\n\n        # Computing EM error\n        gap = ifelse(it.em>minit.em,gap.em,1)\n        if(it.em>1){\n            parlist.old = parlist[[(it.em-gap)]][names(psi.k1)]\n            parlist.new = parlist[[it.em]][names(psi.k1)]\n            zlist.table = data.table(old = zlist[[(it.em-gap)]], new = zlist[[it.em]])\n            ACC = 100*zlist.table[,.N,by=.(old,new)][(old==0 & new==0) | (old==1 & new==1),sum(N)]/M\n        } else{\n            parlist.old = rep(1,length(names(psi.k1)))\n            parlist.new = rep(1,length(names(psi.k1)))\n            ACC = 0\n        }\n\n        MRCPE = max(abs((parlist.new-parlist.old)/parlist.old)) #Max. Abs. Rel. Change. of par. estimates\n        MACPE = max(abs(parlist.new-parlist.old)) #Max. Abs. Change. of par. estimates\n        ARCEL = ifelse(it.em>=2,abs((parlist[[it.em]][['Q']] - parlist[[(it.em-gap)]][['Q']])/parlist[[(it.em-gap)]][['Q']]),0) #Abs. Rel. Change of expected log-likelihood of complete data (Q function)\n        MULTI = c(MRCPE,MACPE,ARCEL,100-ACC)\n        error.em = (it.em>=2)*get(criterion) + (it.em<2)*rep(1,length(get(criterion)))\n        count.em = as.numeric(any(error.em<=epsilon.em))*(it.em>minit.em)*(count.em+1) + 0\n\n        #Outputing history\n        if(!quiet){\n            cat(paste0(c(rep('#',45),'\\n')))\n            cat('\\rIteration: ',it.em,', Error(s): ',paste(formatC(error.em, format = \"e\", digits = 2),collapse = ', '),', Viterbi Agreement: ',round(ACC,2),'%.\\n',sep='')\n            cat(\"\\r\",paste('Q-function: '),parlist[[it.em]][['Q']],\"\\n\")\n            cat(\"\\r\",paste('Max. abs. rel. change of parameter estimates: '),MRCPE,\"\\n\")\n            cat(\"\\r\",paste('Max. abs. change of parameter estimates: '),MACPE,\"\\n\")\n            cat(\"\\r\",paste('Abs. rel. change of Q-function: '),ARCEL,\"\\n\")\n            cat(paste0(c(rep('#',45),'\\n')))\n        }\n    }\n\n    # Organizing output\n    logF <- setnames(as.data.table(logF),c('Background','Enrichment'))\n    logB <- setnames(as.data.table(logB),c('Background','Enrichment'))\n    loglik <- setnames(as.data.table(loglik),c('Background','Enrichment'))\n    mu <- as.data.table(mu)\n    zeroinfl <- as.data.table(HMM.zeroinfl(csi=psi1.k[(ncolControl+2):length(psi1.k)],X.mat=as.matrix(DTvec[,grepl('Dsg',names(DTvec)),with=F]),offset.vec=DTvec[,offset],N=N,M=M))\n\n    if(!quiet){cat('\\nDone!\\n')}\n    return(list('Pi'=pi.k1,'Gamma'=gamma.k1,'Psi'=psi.k1,'Sigma2'=sigma2.k1,'U'=u.k1,\n                'Zeroinfl'=zeroinfl,'Prob'=DT[,.(PostProb1,PostProb2)],'LogF'=logF,'LogB'=logB,'Loglik'=loglik,\n                'Parhist'=as.data.frame(do.call(rbind,parlist)),'Mean'=mu,'Viterbi'=zlist[[it.em]]))\n}\n\nZIHMM.parallel = function(chromosome,ChIP,Control,offset,control){\n    ChIP.sub = subset(ChIP,chr==chromosome);ChIP.sub$chr = NULL; ChIP.sub = as.matrix(ChIP.sub)\n    Control.sub = subset(Control,chr==chromosome);Control.sub$chr = NULL; Control.sub = as.matrix(Control.sub)\n    offset.sub = subset(offset,chr==chromosome);offset.sub$chr = NULL; offset.sub = as.matrix(offset.sub)\n    tmp = ZIHMM(ChIP = ChIP.sub,Control = Control.sub,offset = offset.sub,control=control)\n    return(tmp)\n}\n\nZIMHMM.parallel = function(chromosome,ChIP,Control,offset,random,control){\n    ChIP.sub = subset(ChIP,chr==chromosome);ChIP.sub$chr = NULL; ChIP.sub = as.matrix(ChIP.sub)\n    Control.sub = subset(Control,chr==chromosome);Control.sub$chr = NULL; Control.sub = as.matrix(Control.sub)\n    offset.sub = subset(offset,chr==chromosome);offset.sub$chr = NULL; offset.sub = as.matrix(offset.sub)\n    tmp = ZIMHMM(ChIP = ChIP.sub,Control = Control.sub,offset = offset.sub,random = random,control = control)\n    return(tmp)\n}\n",
    "created" : 1550084724201.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "0|46|23|0|\n25|51|45|0|\n47|71|104|0|\n106|36|108|0|\n110|58|113|0|\n115|64|119|0|\n121|30|126|0|\n128|26|141|0|\n143|83|151|0|\n153|94|220|0|\n222|25|232|0|\n234|24|264|0|\n266|60|277|0|\n279|66|297|0|\n299|79|310|0|\n312|85|329|0|\n331|50|334|0|\n338|77|357|0|\n359|183|510|0|\n513|1|714|0|\n1014|66|1020|0|\n1022|74|1028|0|\n",
    "hash" : "1651312020",
    "id" : "2F497AD4",
    "lastKnownWriteTime" : 1551729717,
    "last_content_update" : 1551729717509,
    "path" : "~/Dropbox/PhD/Research/Project1/ZIMHMM/R/base.R",
    "project_path" : "R/base.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}